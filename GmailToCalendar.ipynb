{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0e86fe0-bd64-44eb-bd2e-e4c38d60aec1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## ðŸ”§ Gmail Job Scanner Web App for Mechanical Fitter Roles\n",
    "\n",
    "This Jupyter Notebook automates the end-to-end process of identifying FIFO shutdown job opportunities for mechanical fitters directly from your Gmail inbox.\n",
    "\n",
    "### ðŸš€ Key Features\n",
    "\n",
    "This app performs the following steps:\n",
    "\n",
    "1. **Authenticate with Gmail & Google Calendar**\n",
    "   Securely connects to your Gmail and Calendar using OAuth 2.0 or token-based authentication.\n",
    "\n",
    "2. **Scan Recent Emails**\n",
    "   Searches your inbox for new or unread emails that may contain job listings.\n",
    "\n",
    "3. **Classify with OpenAI GPT**\n",
    "   Uses an OpenAI language model to analyze each email and determine whether it includes a mechanical fitter job offer.\n",
    "\n",
    "4. **Extract Structured Job Info**\n",
    "   Parses the email content to pull out key information such as:\n",
    "\n",
    "   * Worksite / Company\n",
    "   * Start and end dates\n",
    "   * Pay rates\n",
    "   * Clean shaven policies at the worksite\n",
    "\n",
    "5. **Store Valid Job Offers**\n",
    "   Compiles confirmed job offers into a structured list for easy tracking and debugging.\n",
    "\n",
    "6. **Add Jobs to Google Calendar**\n",
    "   Automatically inserts valid job offers as calendar events with all relevant details.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d14bb2a-8282-4a37-a031-573d66a0bcce",
   "metadata": {},
   "source": [
    "## ðŸ“¦ Step 1: Install Required Python Packages\n",
    "\n",
    "Before running the notebook, make sure all necessary Python libraries are installed. These packages allow the script to authenticate with Google APIs, interact with Gmail and Google Calendar, call the OpenAI API, and manage environment variables securely.\n",
    "### ðŸ“„ `requirements.txt`\n",
    "\n",
    "Create a file named `requirements.txt` and add the following content:\n",
    "\n",
    "```\n",
    "google-api-python-client\n",
    "google-auth\n",
    "google-auth-oauthlib\n",
    "google-auth-httplib2\n",
    "openai\n",
    "requests\n",
    "python-dotenv\n",
    "bs4\n",
    "pytz\n",
    "```\n",
    "\n",
    "You can install all dependencies with:\n",
    "\n",
    "```bash\n",
    "pip install --upgrade -r requirements.txt\n",
    "```\n",
    "Or install for python for your specific environment, e.g. if using anaconda, you may need to run something like:\n",
    "``` bash\n",
    "/Users/dd/opt/anaconda3/bin/python -m pip install --upgrade -r requirements.txt\n",
    "```\n",
    "---\n",
    "\n",
    "## âš™ï¸ GitHub Actions: Install Python Packages\n",
    "\n",
    "In your GitHub Actions workflow `.yaml` file (e.g., `.github/workflows/gmail_job_pipeline.yml`), ensure the following step is included to install the dependencies:\n",
    "\n",
    "```yaml\n",
    "- name: Install dependencies\n",
    "  run: |\n",
    "    python -m pip install --upgrade pip\n",
    "    pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "> âœ… This ensures that GitHub Actions uses the exact same packages as your local or Colab setup.\n",
    "\n",
    "#### _The full .yaml file will be included at the end of this notebook_\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52cf4bcc-8de0-4a24-a982-8c649a47fb70",
   "metadata": {},
   "source": [
    "## ðŸ” Step 2: Authenticate to Gmail and Google Calendar\n",
    "\n",
    "To access Gmail and Google Calendar via the Google APIs, you need to authenticate using **OAuth 2.0**. This allows the app to read emails and create calendar events on your behalf securely.\n",
    "\n",
    "There are **two modes of authentication** depending on your environment:\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ”¹ Local Mode (Interactive)\n",
    "\n",
    "If you're running the script locally:\n",
    "\n",
    "1. **Enable APIs:**\n",
    "\n",
    "   * Go to the [Google Cloud Console](https://console.cloud.google.com/apis/dashboard).\n",
    "   * Create a new project (or select an existing one).\n",
    "   * Enable both the **Gmail API** and **Google Calendar API**.\n",
    "\n",
    "2. **Create OAuth Credentials:**\n",
    "\n",
    "   * Go to **APIs & Services > Credentials**.\n",
    "   * Click **\"Create Credentials\" > OAuth Client ID**.\n",
    "   * Choose **\"Desktop App\"**.\n",
    "   * Download the `credentials.json` file.\n",
    "\n",
    "3. **First Run:**\n",
    "\n",
    "   * When you run the script for the first time:\n",
    "\n",
    "     * It will launch a browser window asking you to log in with your Google account.\n",
    "     * After approval, a `token.json` file will be saved for future access.\n",
    "\n",
    "> ðŸ” On subsequent runs, the script will automatically use the saved `token.json` unless it's expired.\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ”¹ GitHub Actions / Automation Mode\n",
    "\n",
    "For running this in the cloud or in CI (e.g. GitHub Actions), use a **pre-generated OAuth token** in a secure, non-interactive way.\n",
    "\n",
    "#### âœ… How to Generate the Token:\n",
    "\n",
    "1. Complete the steps above in **Local Mode** to create a valid `token.json`.\n",
    "2. Base64-encode the file:\n",
    "\n",
    "   ```bash\n",
    "   base64 token.json > token.json.base64\n",
    "   ```\n",
    "3. Open `token.json.base64` and copy the contents.\n",
    "\n",
    "#### ðŸ” Store as GitHub Secret:\n",
    "\n",
    "1. Go to your GitHub repository â†’ **Settings > Secrets and variables > Actions**.\n",
    "2. Click **\"New repository secret\"**.\n",
    "3. Name it `GMAIL_API_TOKEN_BASE64`.\n",
    "4. Paste the base64-encoded contents.\n",
    "\n",
    "#### ðŸ” In Your Script:\n",
    "\n",
    "Your script should:\n",
    "\n",
    "* Read the `GMAIL_API_TOKEN_BASE64` environment variable.\n",
    "* Decode it and load it in place of `token.json`.\n",
    "\n",
    "```python\n",
    "import os\n",
    "import base64\n",
    "from google.oauth2.credentials import Credentials\n",
    "\n",
    "token_base64 = os.getenv(\"GMAIL_API_TOKEN_BASE64\")\n",
    "if token_base64:\n",
    "    token_data = base64.b64decode(token_base64)\n",
    "    with open(\"token.json\", \"wb\") as f:\n",
    "        f.write(token_data)\n",
    "```\n",
    "\n",
    "> ðŸ” This avoids needing browser logins and ensures secure, automated access in CI.\n",
    "\n",
    "---\n",
    "\n",
    "### âœ… After Authentication\n",
    "\n",
    "The script will create:\n",
    "\n",
    "* A `gmail` service to search for job-related emails.\n",
    "* A `calendar` service to insert calendar events.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd03d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import os\n",
    "\n",
    "GMAIL_API_TOKEN_BASE64 = os.getenv(\"GMAIL_API_TOKEN_BASE64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190afad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m pip install --upgrade pip\n",
    "# !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e12174d-761e-4360-b12b-7b023e80f683",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import base64\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "from google.auth.transport.requests import Request\n",
    "from google.oauth2.credentials import Credentials\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from googleapiclient.discovery import build\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Define the scopes\n",
    "SCOPES = [\n",
    "    'https://www.googleapis.com/auth/gmail.readonly',\n",
    "    'https://www.googleapis.com/auth/calendar'\n",
    "]\n",
    "\n",
    "# Only load .env if not running in GitHub Actions\n",
    "if not os.getenv(\"GITHUB_ACTIONS\"):\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv()\n",
    "\n",
    "# Define the token and credentials file paths for if .env doesn't exist\n",
    "token_file_name = \"token.json\"\n",
    "cred_file_name = \"credentials.json\"\n",
    "\n",
    "\n",
    "def authenticate_google_services(scopes=SCOPES, token_file=token_file_name, cred_file=cred_file_name):\n",
    "    creds = None\n",
    "\n",
    "    # Check if the credentials exist in the .env file\n",
    "    if os.getenv(\"GMAIL_API_TOKEN_BASE64\"):\n",
    "        print(\"[INFO] Found token in .env file. Decoding and using it.\")\n",
    "        token_json_str = base64.b64decode(os.getenv(\"GMAIL_API_TOKEN_BASE64\")).decode('utf-8')\n",
    "        creds_dict = json.loads(token_json_str)\n",
    "        creds = Credentials.from_authorized_user_info(info=creds_dict, scopes=scopes)\n",
    "\n",
    "    # If no token in .env, check if running in GitHub Actions\n",
    "    elif os.getenv(\"GITHUB_ACTIONS\") == \"true\":\n",
    "        print(\"[INFO] Running in GitHub Actions. Loading credentials from env variable.\")\n",
    "        token_json_str = base64.b64decode(os.getenv(\"GMAIL_API_TOKEN_BASE64\")).decode('utf-8')\n",
    "        creds_dict = json.loads(token_json_str)\n",
    "        creds = Credentials.from_authorized_user_info(info=creds_dict, scopes=scopes)\n",
    "\n",
    "    # Local environment: Check if token file exists\n",
    "    elif os.path.exists(token_file):\n",
    "        print(f\"[INFO] Running locally. Loading token from {token_file}.\")\n",
    "        creds = Credentials.from_authorized_user_file(token_file, scopes)\n",
    "\n",
    "        if not creds or not creds.valid:\n",
    "            if creds and creds.expired and creds.refresh_token:\n",
    "                creds.refresh(Request())\n",
    "            else:\n",
    "                print(\"[INFO] Starting OAuth flow for local user.\")\n",
    "                from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "                flow = InstalledAppFlow.from_client_secrets_file(cred_file, scopes)\n",
    "                creds = flow.run_local_server(port=0)\n",
    "            with open(token_file, 'w') as token:\n",
    "                token.write(creds.to_json())\n",
    "\n",
    "    else:\n",
    "        raise RuntimeError(\"No valid authentication method found.\")\n",
    "\n",
    "    # Build the service clients\n",
    "    gmail = build('gmail', 'v1', credentials=creds)\n",
    "    calendar = build('calendar', 'v3', credentials=creds)\n",
    "    return gmail, calendar\n",
    "\n",
    "# def authenticate_google_services(scopes=SCOPES):\n",
    "#     creds = None\n",
    "\n",
    "#     # Check if running in GitHub Actions or another CI environment\n",
    "#     if os.getenv(\"GITHUB_ACTIONS\") == \"true\":\n",
    "#         print(\"[INFO] Running in GitHub Actions. Loading credentials from env variable.\")\n",
    "#         token_json_str = base64.b64decode(os.getenv(\"GMAIL_API_TOKEN_BASE64\")).decode('utf-8')\n",
    "#         creds_dict = json.loads(token_json_str)\n",
    "#         creds = Credentials.from_authorized_user_info(info=creds_dict, scopes=scopes)\n",
    "\n",
    "#     # Local environment\n",
    "#     elif os.path.exists(token_file):\n",
    "#         print(\"[INFO] Running locally. Loading token from\",token_file)\n",
    "#         creds = Credentials.from_authorized_user_file(token_file, scopes)\n",
    "\n",
    "#         if not creds or not creds.valid:\n",
    "#             if creds and creds.expired and creds.refresh_token:\n",
    "#                 creds.refresh(Request())\n",
    "#             else:\n",
    "#                 print(\"[INFO] Starting OAuth flow for local user.\")\n",
    "#                 from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "#                 flow = InstalledAppFlow.from_client_secrets_file(cred_file, scopes)\n",
    "#                 creds = flow.run_local_server(port=0)\n",
    "#             with open(token_file, 'w') as token:\n",
    "#                 token.write(creds.to_json())\n",
    "\n",
    "#     else:\n",
    "#         raise RuntimeError(\"No valid authentication method found.\")\n",
    "\n",
    "#     # Build the service clients\n",
    "#     gmail = build('gmail', 'v1', credentials=creds)\n",
    "#     calendar = build('calendar', 'v3', credentials=creds)\n",
    "#     return gmail, calendar\n",
    "\n",
    "# gmail_service, calendar_service = authenticate_google_services(SCOPES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9244f017",
   "metadata": {},
   "source": [
    "## Step 3: Fetch Recent Job-Related Emails\n",
    "\n",
    "In this step, we connect to Gmail using the authenticated service and extract relevant recent emails that mention job-related keywords.\n",
    "\n",
    "### ðŸ” Email Filtering and Query\n",
    "\n",
    "We use the Gmail API to search for emails received in the past `X` hours using job-specific keywords such as:\n",
    "- `job`, `shutdown`, `fitter`, `fifo`, `shut`, etc.\n",
    "\n",
    "This is done through a **Gmail search query**, making the process efficient and focused on relevant content.\n",
    "\n",
    "### ðŸ“§ Extracting Email Content\n",
    "\n",
    "We define two key functions:\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ”¹ `extract_body(part)`\n",
    "\n",
    "This function recursively searches the email payload for the message body. It handles both:\n",
    "- `text/plain`: directly decodes the base64 content.\n",
    "- `text/html`: decodes and strips HTML tags using BeautifulSoup.\n",
    "\n",
    "> âš ï¸ Gmail messages can be multipart (e.g., containing both HTML and plain text), so we handle nested parts robustly.\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ”¹ `fetch_recent_emails(gmail_service, time_delta_hours=1000, max_results=1000)`\n",
    "\n",
    "This function:\n",
    "1. Calculates the timestamp `X` hours ago (default: 1000 hours).\n",
    "2. Builds a Gmail query to filter recent job-related emails.\n",
    "3. Iterates through the messages returned by the Gmail API.\n",
    "4. Extracts:\n",
    "   - **Subject**\n",
    "   - **Sender**\n",
    "   - **Date Received** (converted to Perth timezone)\n",
    "   - **Email Body** (via `extract_body`)\n",
    "   - **Thread ID** (used for linking later)\n",
    "\n",
    "Each email is returned as a dictionary and added to a list for downstream processing.\n",
    "\n",
    "Docs: \n",
    "https://developers.google.com/workspace/gmail/api/guides/list-messages\n",
    "https://developers.google.com/workspace/gmail/api/reference/rest/v1/users.messages/list\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ“¦ Output Format\n",
    "\n",
    "Each extracted email is returned as a dictionary like:\n",
    "\n",
    "```python\n",
    "{\n",
    "    'subject': 'Job Offer - Shutdown at BHP',\n",
    "    'sender': 'recruiter@example.com',\n",
    "    'body': 'Hi, we are looking for fitters...',\n",
    "    'thread_id': '17923a4a9efc1234',\n",
    "    'received_datetime': '2025-07-27 09:30:00 AWST'\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08964389-a7ce-4a58-90a2-ce8ff604cd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def extract_body(part):\n",
    "    # If the part has its own parts, search them\n",
    "    if 'parts' in part:\n",
    "        for subpart in part['parts']:\n",
    "            text = extract_body(subpart)\n",
    "            if text:\n",
    "                return text\n",
    "    else:\n",
    "        # Try plain text first\n",
    "        if part.get('mimeType') == 'text/plain' and 'data' in part.get('body', {}):\n",
    "            return base64.urlsafe_b64decode(part['body']['data']).decode('utf-8')\n",
    "        # If not, fall back to HTML and strip tags\n",
    "        elif part.get('mimeType') == 'text/html' and 'data' in part.get('body', {}):\n",
    "            html = base64.urlsafe_b64decode(part['body']['data']).decode('utf-8')\n",
    "            return BeautifulSoup(html, 'html.parser').get_text()\n",
    "    return ''\n",
    "\n",
    "import time\n",
    "import pytz\n",
    "\n",
    "def fetch_recent_emails(gmail_service, time_delta_hours=1000, max_results=1000):\n",
    "    # Calculate UNIX timestamp for 24 hours ago\n",
    "    start_time = datetime.utcnow() - timedelta(hours=time_delta_hours)\n",
    "    after_timestamp = int(time.mktime(start_time.timetuple()))\n",
    "    \n",
    "    print(\"time_delta_hours:\",time_delta_hours)\n",
    "    print(\"After timestamp:\", after_timestamp)\n",
    "    print(\"UTC time:\", datetime.utcfromtimestamp(after_timestamp))\n",
    "\n",
    "    # Filter the emails being searched. Doing this general filter is much more efficient than a GPT\n",
    "    query = (\n",
    "        f\"after:{after_timestamp} \"\n",
    "        + '(job OR shutdown OR shutdowns OR fitter OR fitters OR fifo OR shut OR shuts)'\n",
    "    )\n",
    "    \n",
    "\n",
    "    # Use the query to fetch only recent emails\n",
    "    results = gmail_service.users().messages().list(\n",
    "        userId='me',\n",
    "        maxResults=max_results,\n",
    "        q=query\n",
    "    ).execute()\n",
    "\n",
    "    messages = results.get('messages', [])\n",
    "    emails = []\n",
    "\n",
    "    for msg in messages:\n",
    "        msg_data = gmail_service.users().messages().get(userId='me', id=msg['id'], format='full').execute()\n",
    "        payload = msg_data['payload']\n",
    "        headers = payload.get('headers', [])\n",
    "        subject = next((h['value'] for h in headers if h['name'] == 'Subject'), '(No Subject)')\n",
    "        sender = next((h['value'] for h in headers if h['name'] == 'From'), '(Unknown)')\n",
    "        \n",
    "        # Convert internalDate to Perth timezone\n",
    "        internal_ts = int(msg_data.get('internalDate', 0)) / 1000  # in seconds\n",
    "        utc_dt = datetime.utcfromtimestamp(internal_ts).replace(tzinfo=pytz.utc)\n",
    "        perth_dt = utc_dt.astimezone(pytz.timezone('Australia/Perth'))\n",
    "        received_datetime = perth_dt.strftime('%Y-%m-%d %H:%M:%S %Z')\n",
    "        \n",
    "        thread_id = msg['threadId']\n",
    "\n",
    "        body = extract_body(payload).replace('\\r\\n', '\\n').replace('\\r', '\\n')\n",
    "\n",
    "        emails.append({\n",
    "            'subject': subject,\n",
    "            'sender': sender,\n",
    "            'body': body,\n",
    "            'thread_id': thread_id,\n",
    "            'received_datetime' : received_datetime\n",
    "        })\n",
    "\n",
    "    return emails"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536882af",
   "metadata": {},
   "source": [
    "# Step 4: Use OpenAI GPT to extract the job details"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5f35f9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸ”‘ How to Get Your `OPENAI_API_KEY`\n",
    "\n",
    "Follow these steps to generate and access your OpenAI API key:\n",
    "\n",
    "### 1. Create an OpenAI Account\n",
    "\n",
    "If you donâ€™t already have one, go to [https://platform.openai.com/signup](https://platform.openai.com/signup) and sign up.\n",
    "\n",
    "### 2. Go to the API Keys Page\n",
    "\n",
    "Once logged in:\n",
    "\n",
    "* Visit [https://platform.openai.com/api-keys](https://platform.openai.com/api-keys)\n",
    "\n",
    "Or navigate:\n",
    "\n",
    "* Click your profile icon in the top-right corner.\n",
    "* Choose **\"API Keys\"** from the dropdown menu.\n",
    "\n",
    "### 3. Create a New Secret Key\n",
    "\n",
    "* Click **â€œ+ Create new secret keyâ€**\n",
    "* Give it a name (optional, for your reference)\n",
    "* Click **Create Secret Key**\n",
    "* **Copy it immediately** â€“ you **wonâ€™t be able to view it again**!\n",
    "\n",
    "Example format of the key:\n",
    "\n",
    "```\n",
    "sk-XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
    "```\n",
    "\n",
    "### 4. Store the Key Securely\n",
    "\n",
    "You can use a `.env` file in your project:\n",
    "\n",
    "```env\n",
    "OPENAI_API_KEY=sk-XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
    "```\n",
    "\n",
    "Or add it as a GitHub Secret for GitHub Actions:\n",
    "\n",
    "* Go to your repo â†’ **Settings** â†’ **Secrets and variables** â†’ **Actions**\n",
    "* Click **â€œNew repository secretâ€**\n",
    "* Name: `OPENAI_API_KEY`\n",
    "* Value: *paste your key*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a03ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load API key\n",
    "OPENAI_API_KEY=os.getenv(\"OPENAI_API_KEY\")\n",
    "# print(OPENAI_API_KEY)\n",
    "\n",
    "# Get current date in YYYY-MM-DD\n",
    "current_year = time.gmtime().tm_year \n",
    "current_month = time.gmtime().tm_mon\n",
    "current_day = time.gmtime().tm_mday \n",
    "current_date = f'{current_year}-{current_month:02d}-{current_day:02d}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c71933e-6371-4122-b053-20810e5a65e1",
   "metadata": {},
   "source": [
    "## ðŸ› ï¸ Prompt Engineering: Job Opportunity Extraction for Mining Shutdowns\n",
    "\n",
    "### ðŸŽ¯ GPT Instructions\n",
    "\n",
    "You are an expert assistant specialized in identifying **mechanical fitter** and **rigger** job opportunities in **mining shutdowns across Australia**.\n",
    "\n",
    "Your task is to **analyze the full content of an email thread** and return a structured JSON object **only if** there is a **genuine and current** job opportunity.\n",
    "\n",
    "* If **no valid opportunity** is detected, return:\n",
    "\n",
    "  ```json\n",
    "  { \"is_work_opportunity\": false, ...all other fields as empty lists... }\n",
    "  ```\n",
    "\n",
    "---\n",
    "\n",
    "### âœ… Relevance Criteria\n",
    "\n",
    "Only return a result if the email includes **at least one** of the following:\n",
    "\n",
    "* A job ad, request for availability, or invitation to apply\n",
    "* A confirmed shutdown schedule or a **clear start/end date**\n",
    "\n",
    "> âš ï¸ *Ignore generic rosters and projects longer than 1 month.*\n",
    "\n",
    "> âš ï¸ *Ignore jobs without a start date and an end date.*\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ“¦ Data to Extract (All as Lists)\n",
    "\n",
    "Each field below must be extracted as a list. Ensure **all lists are the same length**.\n",
    "Duplicate or align values across fields as needed. Use **dummy values** if specific details are missing.\n",
    "\n",
    "| Field              | Description                                                                      |\n",
    "| ------------------ | -------------------------------------------------------------------------------- |\n",
    "| `workplace`        | Mine or site names (e.g., \"Roy Hill\", \"FMG Cloudbreak\")                          |\n",
    "| `start_date`       | Job start date in `YYYY-MM-DD` format. Use `{current_date}` as reference.        |\n",
    "| `end_date`         | Job end date in `YYYY-MM-DD` format                                              |\n",
    "| `day_shift_rate`   | Pay rate for day shift (float, e.g., 65.00)                                     |\n",
    "| `night_shift_rate` | Pay rate for night shift (float, e.g., 72.50)                                   |\n",
    "| `position`         | Must be either `\"Fitter\"` or `\"Rigger\"`                                          |\n",
    "| `clean_shaven`     | `true` if clean-shaven requirement is mentioned, otherwise `false`               |\n",
    "| `client_name`      | Derived from senderâ€™s domain (e.g., `downergroup.com.au` â†’ `downergroup`)        |\n",
    "| `contact_number`   | Digits only (no spaces or symbols). If more than one is present, use the mobile. |           \n",
    "| `email_address`    | Valid contact email(s) from the thread                                           |\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ§¾ Output Format\n",
    "\n",
    "Return the following JSON object, with **all keys present**, even if empty:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"is_work_opportunity\": true,\n",
    "  \"workplace\": [],\n",
    "  \"start_date\": [],\n",
    "  \"end_date\": [],\n",
    "  \"day_shift_rate\": [],\n",
    "  \"night_shift_rate\": [],\n",
    "  \"position\": [],\n",
    "  \"clean_shaven\": [],\n",
    "  \"client_name\": [],\n",
    "  \"contact_number\": [],\n",
    "  \"email_address\": []\n",
    "}\n",
    "```\n",
    "\n",
    "> â— Ensure consistency across list lengths. Entries must align row-wise (i.e., details from the same job in the same index).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b730ce-fdfd-4b93-8387-2eaaa67962af",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_INSTRUCTIONS= f\"\"\"\n",
    "You are an expert assistant specialized in identifying **mechanical fitter** and **rigger** job opportunities in **mining shutdowns across Australia**.\n",
    "\n",
    "Your task is to **analyze the full content of an email thread** and return a structured JSON object **only if** there is a **genuine and current** job opportunity.\n",
    "\n",
    "* If **no valid opportunity** is detected, return:\n",
    "\n",
    "  ```json\n",
    "  {{ \"is_work_opportunity\": false, ...all other fields as empty lists... }}\n",
    "  ```\n",
    "\n",
    "---\n",
    "\n",
    "### âœ… Relevance Criteria\n",
    "\n",
    "Only return a result if the email includes **at least one** of the following:\n",
    "\n",
    "* A job ad, request for availability, or invitation to apply\n",
    "* A confirmed shutdown schedule or a **clear start and end date**\n",
    "\n",
    "> âš ï¸ *Ignore generic rosters and projects longer than 1 month.*\n",
    "\n",
    "> âš ï¸ *Ignore jobs without a start date and an end date.*\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ“¦ Data to Extract (All as Lists)\n",
    "\n",
    "Each field below must be extracted as a list. Ensure **all lists are the same length**.\n",
    "Duplicate or align values across fields as needed. Use **dummy values** if specific details are missing.\n",
    "\n",
    "| Field              | Description                                                                      |\n",
    "| ------------------ | -------------------------------------------------------------------------------- |\n",
    "| `workplace`        | Mine or site names (e.g., \"Roy Hill\", \"FMG Cloudbreak\")                          |\n",
    "| `start_date`       | Job start date in `YYYY-MM-DD` format. Use `{current_date}` as reference.        |\n",
    "| `end_date`         | Job end date in `YYYY-MM-DD` format                                              |\n",
    "| `day_shift_rate`   | Pay rate for day shift (float, e.g., 65.00)                                     |\n",
    "| `night_shift_rate` | Pay rate for night shift (float, e.g., 72.50)                                   |\n",
    "| `position`         | Must be either `\"Fitter\"` or `\"Rigger\"`                                          |\n",
    "| `clean_shaven`     | `true` if clean-shaven requirement is mentioned, otherwise `false`               |\n",
    "| `client_name`      | Derived from senderâ€™s domain (e.g., `downergroup.com.au` â†’ `downergroup`)        |\n",
    "| `contact_number`   | Digits only (no spaces or symbols). If more than one is present, use the mobile. |\n",
    "| `email_address`    | Valid contact email(s) from the thread                                           |\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ§¾ Output Format\n",
    "\n",
    "Return the following JSON object, with **all keys present**, even if empty:\n",
    "\n",
    "```json\n",
    "{{\n",
    "  \"is_work_opportunity\": true,\n",
    "  \"workplace\": [],\n",
    "  \"start_date\": [],\n",
    "  \"end_date\": [],\n",
    "  \"day_shift_rate\": [],\n",
    "  \"night_shift_rate\": [],\n",
    "  \"position\": [],\n",
    "  \"clean_shaven\": [],\n",
    "  \"client_name\": [],\n",
    "  \"contact_number\": [],\n",
    "  \"email_address\": []\n",
    "}}\n",
    "```\n",
    "\n",
    "> â— Ensure consistency across list lengths. Entries must align row-wise (i.e., details from the same job in the same index).\n",
    "\n",
    "---\n",
    "\"\"\"\n",
    "# PROMPT_INSTRUCTIONS = f\"\"\"\n",
    "# You are an expert assistant for detecting job opportunities for **mechanical fitters** or **riggers** in **mining shutdowns** in Australia.\n",
    "\n",
    "# Analyze the full email thread content and return a structured JSON object **only if** there is a genuine and current work opportunity. Otherwise, return `\"is_work_opportunity\": false` and leave all other fields as empty lists.\n",
    "\n",
    "# ## Relevance Criteria\n",
    "# Only return a result if the email includes one of:\n",
    "# - A job ad, invitation to apply, or request for availability\n",
    "# - Shutdown schedule confirmation or a start/end date\n",
    "# - (Ignore rosters)\n",
    "\n",
    "# ## Extraction Fields (all as **lists**):\n",
    "# - `workplace`: Names of mines/sites.\n",
    "# - `start_date`, `end_date`: Format as `YYYY-MM-DD`. Today is {current_date}.\n",
    "# - `day_shift_rate`, `night_shift_rate`: Float values (e.g., 655.00).\n",
    "# - `position`: \"Fitter\" or \"Rigger\".\n",
    "# - `clean_shaven`: True or False.\n",
    "# - `client_name`: Extract from sender's domain; take only the first part (e.g., from `downergroup.com.au` â†’ `downergroup`).\n",
    "# - `contact_number`: Digits only, no spaces.\n",
    "# - `email_address`: Valid contact emails.\n",
    "\n",
    "# > Ensure all lists are the same length. Duplicate or align entries as needed. Use dummy values if specific details are missing.\n",
    "\n",
    "# ## Output Format\n",
    "# Return the following JSON object with **all keys present**, even if values are empty:\n",
    "# {{\n",
    "#   \"is_work_opportunity\": true,\n",
    "#   \"workplace\": [...],\n",
    "#   \"start_date\": [...],\n",
    "#   \"end_date\": [...],\n",
    "#   \"day_shift_rate\": [...],\n",
    "#   \"night_shift_rate\": [...],\n",
    "#   \"position\": [...],\n",
    "#   \"clean_shaven\": [...],\n",
    "#   \"client_name\": [...],\n",
    "#   \"contact_number\": [...],\n",
    "#   \"email_address\": [...]\n",
    "# }}\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e54e4d0-da1e-46bc-a5ef-279c570343c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "def query_gpt_model(email_body, MODEL=\"gpt-4o\", INSTRUCTIONS=PROMPT_INSTRUCTIONS, INPUT=\"\"):\n",
    "    return client.responses.create(\n",
    "        model=MODEL,\n",
    "        instructions=INSTRUCTIONS,\n",
    "        input=INPUT + email_body  # If `input` is expected as a plain prompt\n",
    "    )\n",
    "\n",
    "\n",
    "def remove_code_fences(text):\n",
    "    lines = text.strip().splitlines()\n",
    "    if lines and lines[0].strip().startswith(\"```\"):\n",
    "        lines = lines[1:]  # remove first line\n",
    "    if lines and lines[-1].strip() == \"```\":\n",
    "        lines = lines[:-1]  # remove last line\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "import json\n",
    "import traceback\n",
    "\n",
    "def process_emails_for_jobs(emails):\n",
    "    job_offers = []\n",
    "\n",
    "    for email_obj in emails:\n",
    "        email_preview = email_obj.get('subject', '')[:50] or email_obj.get('body', '')[:50]\n",
    "        \n",
    "        try:\n",
    "            model_output = query_gpt_model(email_obj['body']).output_text\n",
    "            cleaned_output = remove_code_fences(model_output)\n",
    "            parsed = json.loads(cleaned_output)\n",
    "        except Exception as e:\n",
    "            # Don't debug here â€” only care if it's a work opportunity\n",
    "            continue\n",
    "        \n",
    "        # Only handle if it's flagged as a work opportunity\n",
    "        if parsed.get('is_work_opportunity') is True:\n",
    "            try:\n",
    "                required_keys = ['workplace', 'start_date',\n",
    "                                 'end_date', 'day_shift_rate', 'night_shift_rate', 'position',\n",
    "                                 'clean_shaven', 'client_name', 'contact_number', 'email_address']\n",
    "\n",
    "                # Check key presence\n",
    "                if not all(key in parsed for key in required_keys):\n",
    "                    print(f\"[DEBUG] Missing keys in GPT output for email preview: '{email_preview}'\")\n",
    "                    continue\n",
    "\n",
    "                # Step 1: Collect list lengths\n",
    "                list_lengths = {key: len(parsed[key]) for key in required_keys if isinstance(parsed[key], list)}\n",
    "\n",
    "                # Step 2: Check for inconsistency\n",
    "                if len(set(list_lengths.values())) != 1:\n",
    "                    print(f\"[DEBUG] Inconsistent list lengths in work data for email: '{email_preview}'\")\n",
    "                    for key, length in list_lengths.items():\n",
    "                        print(f\"  - {key}: {length} -> {parsed[key]}\")\n",
    "\n",
    "                    # Step 3: Normalize by padding with last item (or empty string if list is empty)\n",
    "                    max_length = max(list_lengths.values())\n",
    "                    for key in required_keys:\n",
    "                        if isinstance(parsed.get(key), list):\n",
    "                            current_list = parsed[key]\n",
    "                            while len(current_list) < max_length:\n",
    "                                current_list.append(current_list[-1] if current_list else \"\")\n",
    "\n",
    "\n",
    "                # Extract and store job offers\n",
    "                max_len = max(list_lengths.values())\n",
    "                for i in range(max_len):\n",
    "                    job_offers.append({\n",
    "                        'workplace': parsed['workplace'][i],\n",
    "                        'start_date': parsed['start_date'][i],\n",
    "                        'end_date': parsed['end_date'][i],\n",
    "                        'day_shift_rate': parsed['day_shift_rate'][i],\n",
    "                        'night_shift_rate': parsed['night_shift_rate'][i],\n",
    "                        'position': parsed['position'][i],\n",
    "                        'clean_shaven': parsed['clean_shaven'][i],\n",
    "                        'client_name': parsed['client_name'][i],\n",
    "                        'contact_number': parsed['contact_number'][i],\n",
    "                        'email_address': email_obj['sender'],\n",
    "                        'thread_id': email_obj['thread_id'],\n",
    "                        'email_thread_link': f\"https://mail.google.com/mail/u/0/#inbox/{email_obj['thread_id']}\",\n",
    "                        'received_datetime': email_obj['received_datetime'],\n",
    "                        'email_subject': email_obj['subject']\n",
    "                    })\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"[DEBUG] Failed to process work opportunity from email: '{email_preview}'\")\n",
    "                print(f\"[DEBUG] Error: {e}\")\n",
    "                traceback.print_exc()\n",
    "\n",
    "    return job_offers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6fcd38-1c75-432c-baaf-9d07035298b5",
   "metadata": {},
   "source": [
    "## Step 6: Add entries to Google calendar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381e07f0-8939-40d8-9900-d24c56063530",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_google_calendars(calendar_service):\n",
    "    calendars_result = calendar_service.calendarList().list().execute()\n",
    "    calendars = calendars_result.get('items', [])\n",
    "\n",
    "    for cal in calendars:\n",
    "        print(f\"{cal.get('summary')}\\t: {cal.get('id')}\")\n",
    "# list_google_calendars(calendar_service)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a5bfdc-3789-4edb-916f-aee5a0479021",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_calendar(calendar_service, calendar_id=os.getenv(\"CALENDAR_ID\")):\n",
    "    page_token = None\n",
    "    while True:\n",
    "        events = calendar_service.events().list(\n",
    "            calendarId=calendar_id,\n",
    "            pageToken=page_token,\n",
    "            showDeleted=False,\n",
    "            maxResults=2500  # API max limit per page\n",
    "        ).execute()\n",
    "\n",
    "        items = events.get('items', [])\n",
    "        if not items:\n",
    "            print(\"No more events to delete.\")\n",
    "            break\n",
    "\n",
    "        for event in items:\n",
    "            try:\n",
    "                calendar_service.events().delete(\n",
    "                    calendarId=calendar_id,\n",
    "                    eventId=event['id']\n",
    "                ).execute()\n",
    "                print(f\"Deleted: {event.get('summary', 'No Title')}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to delete event: {e}\")\n",
    "\n",
    "        page_token = events.get('nextPageToken')\n",
    "        if not page_token:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260df5dd-45f1-4926-9697-2be4da4cb974",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_jobs_to_calendar(job_offers, calendar_service, calendar_id=os.getenv(\"CALENDAR_ID\")):\n",
    "    for job in job_offers:\n",
    "        summary = f\"{job['workplace']} | ${job['day_shift_rate']} DS / ${job['night_shift_rate']} NS | {job['client_name']}\"\n",
    "        start_date = job['start_date']\n",
    "        \n",
    "        # Add 1 day to the end date, as event ends at 00:00 of the end date\n",
    "        end_date_obj = datetime.strptime(job['end_date'], \"%Y-%m-%d\").date() + timedelta(days=1)\n",
    "        end_date = end_date_obj.strftime(\"%Y-%m-%d\")  # convert back to string\n",
    "\n",
    "        # To search for the email on that specific day, I need to search from the day before until the day after\n",
    "        # First, parse the string into a datetime object\n",
    "        received_str = job['received_datetime'].rsplit(' ', 1)[0]  # removes ' AWST'\n",
    "        received_dt = datetime.strptime(received_str, \"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "        # Then get the date and apply timedelta\n",
    "        search_start_date = received_dt.date() - timedelta(days=1)\n",
    "        search_end_date = received_dt.date() + timedelta(days=1)\n",
    "\n",
    "        # Define the event to insert\n",
    "        event = {\n",
    "            'summary': summary,\n",
    "            'description': f\"\"\"\n",
    "Search this in gmail:\n",
    "from:{job['email_address']} after:{search_start_date} before:{search_end_date} subject:{job['email_subject']}\n",
    "\n",
    "Link to email (only works for desktop): {job['email_thread_link']}\n",
    "\n",
    "Client: {job['client_name']}\n",
    "Site: {job['workplace']}\n",
    "Day Shift Rate: {job['day_shift_rate']} /hr\n",
    "Night Shift Rate: {job['night_shift_rate']} /hr\n",
    "\n",
    "Position: {job['position']}\n",
    "Clean Shaven: {job['clean_shaven']}\n",
    "\n",
    "Contact Email: {job['email_address']}\n",
    "Phone: {job['contact_number']}\n",
    "\"\"\",\n",
    "            'start': {\n",
    "                'date': start_date,\n",
    "                'timeZone': 'Australia/Perth',\n",
    "            },\n",
    "            'end': {\n",
    "                'date': end_date,\n",
    "                'timeZone': 'Australia/Perth',\n",
    "            },\n",
    "            'event_type': 'workingLocation',\n",
    "            'location': f\"{job['workplace']}\"\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            # Search for existing events with the same summary on the same day\n",
    "            existing_events = calendar_service.events().list(\n",
    "                calendarId=calendar_id,\n",
    "                q=summary,\n",
    "                timeMin=f\"{start_date}T00:00:00+08:00\",\n",
    "                timeMax=f\"{end_date}T23:59:59+08:00\",\n",
    "                singleEvents=True\n",
    "            ).execute()\n",
    "\n",
    "            if existing_events.get('items'):\n",
    "                print(f\"Skipped duplicate event: {summary} on {start_date}\")\n",
    "                continue  # Skip adding this event\n",
    "\n",
    "            # Insert new event\n",
    "            event_result = calendar_service.events().insert(calendarId=calendar_id, body=event).execute()\n",
    "            print(\"Calendar entry added:\", summary, event_result.get('htmlLink'))\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"Failed to add calendar entry:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c77bc77-7692-4e1f-87fd-90719e974818",
   "metadata": {},
   "source": [
    "# Main\n",
    "This is the function that is run online by scheduling.\n",
    "\n",
    "To make this function runable, run the following command:\n",
    "```bash\n",
    "jupyter nbconvert --to script GmailToCalendar.ipynb --output main\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9354ae-eb92-4c64-85e5-df7b7c4ae309",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    #- Get access to gmail and calendar\n",
    "    gmail_service, calendar_service = authenticate_google_services()\n",
    "    print(\"\\tGOOGLE AUTHENITICATED\\n\\n\")\n",
    "    \n",
    "    #- Get job offers from emails\n",
    "    num_days = 7\n",
    "    num_hours = num_days * 24\n",
    "    max_emails = 10000\n",
    "    emails = fetch_recent_emails(gmail_service, time_delta_hours=num_hours,max_results=max_emails)\n",
    "    print(f\"\\t{len(emails)} EMAILS RETRIEVED\\n\\n\")\n",
    "\n",
    "    #- Pass the emails to GPT to extract job information\n",
    "    job_offers = process_emails_for_jobs(emails)\n",
    "    print(f\"\\t{len(job_offers)} JOB OFFERS EXTRACTED\\n\\n\")\n",
    "    \n",
    "    #- Create calendar entries for each job \n",
    "    CALENDAR_ID=os.getenv(\"CALENDAR_ID\")\n",
    "    print(\"CALENDAR_ID\", CALENDAR_ID)\n",
    "    # Optionally clear the calendar of all entries for testing\n",
    "#     clear_calendar(calendar_service)\n",
    "    add_jobs_to_calendar(job_offers,calendar_service)\n",
    "    print(\"CALENDAR ENTRIES ADDED\\n\\n\")\n",
    "    \n",
    "    pass\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fb39ae",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f852f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#- Get access to gmail and calendar\n",
    "gmail_service, calendar_service = authenticate_google_services()\n",
    "print(\"\\tGOOGLE AUTHENITICATED\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3099738b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#- Get job offers from emails\n",
    "num_days = 1\n",
    "num_hours = num_days * 24\n",
    "# max_emails = 10000\n",
    "max_emails = 1\n",
    "emails = fetch_recent_emails(gmail_service, time_delta_hours=num_hours,max_results=max_emails)\n",
    "print(f\"\\t{len(emails)} EMAILS RETRIEVED\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a41c654",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(emails[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc2e99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#- Pass the emails to GPT to extract job information\n",
    "job_offers = process_emails_for_jobs(emails)\n",
    "print(f\"\\t{len(job_offers)} JOB OFFERS EXTRACTED\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0aa4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "for job in job_offers:\n",
    "#     print(json.dumps(job,indent=4))\n",
    "    print(job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5af0265",
   "metadata": {},
   "outputs": [],
   "source": [
    "#- Create calendar entries for each job \n",
    "CALENDAR_ID=os.getenv(\"CALENDAR_ID\")\n",
    "print(\"CALENDAR_ID\", CALENDAR_ID)\n",
    "# Optionally clear the calendar of all entries for testing\n",
    "#     clear_calendar(calendar_service)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d18b100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gmail_service, calendar_service = authenticate_google_services()\n",
    "# clear_calendar(calendar_service)\n",
    "add_jobs_to_calendar(job_offers,calendar_service)\n",
    "print(\"CALENDAR ENTRIES ADDED\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
