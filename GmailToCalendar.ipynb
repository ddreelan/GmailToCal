{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0e86fe0-bd64-44eb-bd2e-e4c38d60aec1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Gmail Job Scanner Web App for Mechanical Fitter Roles\n",
    "\n",
    "This Jupyter notebook implements a full pipeline that:\n",
    "- 1. Authenticates to Gmail.\n",
    "- 2. Scans recent emails.\n",
    "- 3. Uses a free GPT model (via DeepInfra or Hugging Face) to determine if an email contains a job offer for a mechanical fitter.\n",
    "- 4. Extracts structured data (worksite, pay, dates, etc.).\n",
    "- 5. Saves valid job offers to a list.\n",
    "- 6. Adds each job offer to Google Calendar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d14bb2a-8282-4a37-a031-573d66a0bcce",
   "metadata": {},
   "source": [
    "## Step 1: Install Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068f8338",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --quiet --upgrade google-api-python-client google-auth google-auth-oauthlib google-auth-httplib2 openai requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52cf4bcc-8de0-4a24-a982-8c649a47fb70",
   "metadata": {},
   "source": [
    "## Step 2: Authenticate to Gmail and Google Calendar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e12174d-761e-4360-b12b-7b023e80f683",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import base64\n",
    "import email\n",
    "from datetime import datetime, timedelta\n",
    "from google.auth.transport.requests import Request\n",
    "from google.oauth2.credentials import Credentials\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from googleapiclient.discovery import build\n",
    "\n",
    "# Define the scopes\n",
    "SCOPES = [\n",
    "    'https://www.googleapis.com/auth/gmail.readonly',\n",
    "    'https://www.googleapis.com/auth/calendar'\n",
    "]\n",
    "\n",
    "# Authenticate and create service clients\n",
    "def authenticate_google_services(token_file='token.json',cred_file='credentials.json',scopes=SCOPES):\n",
    "    creds = None\n",
    "    if os.path.exists(token_file):\n",
    "        creds = Credentials.from_authorized_user_file(token_file, scopes)\n",
    "    if not creds or not creds.valid:\n",
    "        if creds and creds.expired and creds.refresh_token:\n",
    "            creds.refresh(Request())\n",
    "        else:\n",
    "            flow = InstalledAppFlow.from_client_secrets_file(cred_file, scopes)\n",
    "            creds = flow.run_local_server(port=0)\n",
    "        with open(token_file, 'w') as token:\n",
    "            token.write(creds.to_json())\n",
    "\n",
    "    gmail = build('gmail', 'v1', credentials=creds)\n",
    "    calendar = build('calendar', 'v3', credentials=creds)\n",
    "    return gmail, calendar\n",
    "\n",
    "gmail_service, calendar_service = authenticate_google_services()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1b7d85-2dea-481f-843c-94f860007601",
   "metadata": {},
   "source": [
    "## Step 3: Fetch Recent Emails\n",
    "Docs: \n",
    "\n",
    "https://developers.google.com/workspace/gmail/api/guides/list-messages\n",
    "\n",
    "https://developers.google.com/workspace/gmail/api/reference/rest/v1/users.messages/list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787e22fb-0973-47fb-980d-c77fb064ba98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def extract_body(part):\n",
    "    # If the part has its own parts, search them\n",
    "    if 'parts' in part:\n",
    "        for subpart in part['parts']:\n",
    "            text = extract_body(subpart)\n",
    "            if text:\n",
    "                return text\n",
    "    else:\n",
    "        # Try plain text first\n",
    "        if part.get('mimeType') == 'text/plain' and 'data' in part.get('body', {}):\n",
    "            return base64.urlsafe_b64decode(part['body']['data']).decode('utf-8')\n",
    "        # If not, fall back to HTML and strip tags\n",
    "        elif part.get('mimeType') == 'text/html' and 'data' in part.get('body', {}):\n",
    "            html = base64.urlsafe_b64decode(part['body']['data']).decode('utf-8')\n",
    "            return BeautifulSoup(html, 'html.parser').get_text()\n",
    "    return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08964389-a7ce-4a58-90a2-ce8ff604cd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import pytz\n",
    "\n",
    "def fetch_recent_emails(gmail_service, time_delta_hours=1000, max_results=1000):\n",
    "    # Calculate UNIX timestamp for 24 hours ago\n",
    "    start_time = datetime.utcnow() - timedelta(hours=time_delta_hours)\n",
    "    after_timestamp = int(time.mktime(start_time.timetuple()))\n",
    "    \n",
    "    print(\"time_delta_hours:\",time_delta_hours)\n",
    "    print(\"After timestamp:\", after_timestamp)\n",
    "    print(\"UTC time:\", datetime.utcfromtimestamp(after_timestamp))\n",
    "\n",
    "    # Filter the emails being searched. Doing this general filter is much more efficient than a GPT\n",
    "    query = (\n",
    "        f\"after:{after_timestamp} \"\n",
    "        + '(job OR shutdown OR shutdowns OR fitter OR fitters OR fifo OR shut OR shuts)'\n",
    "    )\n",
    "    \n",
    "\n",
    "    # Use the query to fetch only recent emails\n",
    "    results = gmail_service.users().messages().list(\n",
    "        userId='me',\n",
    "        maxResults=max_results,\n",
    "        q=query\n",
    "    ).execute()\n",
    "\n",
    "    messages = results.get('messages', [])\n",
    "    emails = []\n",
    "\n",
    "    for msg in messages:\n",
    "        msg_data = gmail_service.users().messages().get(userId='me', id=msg['id'], format='full').execute()\n",
    "        payload = msg_data['payload']\n",
    "        headers = payload.get('headers', [])\n",
    "        subject = next((h['value'] for h in headers if h['name'] == 'Subject'), '(No Subject)')\n",
    "        sender = next((h['value'] for h in headers if h['name'] == 'From'), '(Unknown)')\n",
    "        \n",
    "        # Convert internalDate to Perth timezone\n",
    "        internal_ts = int(msg_data.get('internalDate', 0)) / 1000  # in seconds\n",
    "        utc_dt = datetime.utcfromtimestamp(internal_ts).replace(tzinfo=pytz.utc)\n",
    "        perth_dt = utc_dt.astimezone(pytz.timezone('Australia/Perth'))\n",
    "        received_datetime = perth_dt.strftime('%Y-%m-%d %H:%M:%S %Z')\n",
    "        \n",
    "        thread_id = msg['threadId']\n",
    "\n",
    "        body = extract_body(payload).replace('\\r\\n', '\\n').replace('\\r', '\\n')\n",
    "\n",
    "        emails.append({\n",
    "            'subject': subject,\n",
    "            'sender': sender,\n",
    "            'body': body,\n",
    "            'thread_id': thread_id,\n",
    "            'received_datetime' : received_datetime\n",
    "        })\n",
    "\n",
    "    return emails"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c71933e-6371-4122-b053-20810e5a65e1",
   "metadata": {},
   "source": [
    "## Step 4: Send to GPT for Extraction\n",
    "\n",
    "# Prompt Engineering\n",
    "\n",
    "## Instructions to GPT\n",
    "You are an expert assistant for detecting job opportunities for **mechanical fitters** or **riggers** in **mining shutdowns** in Australia.\n",
    "\n",
    "Analyze the full email thread content and return a structured JSON object **only if** there is a genuine and current work opportunity. Otherwise, return `\"is_work_opportunity\": false` and leave all other fields as empty lists.\n",
    "\n",
    "## Relevance Criteria\n",
    "Only return a result if the email includes one of:\n",
    "- A job ad, invitation to apply, or request for availability\n",
    "- Shutdown schedule confirmation or a start/end date\n",
    "- (Ignore rosters)\n",
    "\n",
    "## Extraction Fields (all as **lists**):\n",
    "- `workplace`: Names of mines/sites.\n",
    "- `start_date`, `end_date`: Format as `YYYY-MM-DD`. Today is {current_date}.\n",
    "- `day_shift_rate`, `night_shift_rate`: Float values (e.g., 655.00).\n",
    "- `position`: \"Fitter\" or \"Rigger\".\n",
    "- `clean_shaven`: True or False.\n",
    "- `client_name`: Extract from sender's domain; take only the first part (e.g., from `downergroup.com.au` â†’ `downergroup`).\n",
    "- `contact_number`: Digits only, no spaces.\n",
    "- `email_address`: Valid contact emails.\n",
    "\n",
    "> Ensure all lists are the same length. Duplicate or align entries as needed. Use dummy values if specific details are missing.\n",
    "\n",
    "## Output Format\n",
    "Return the following JSON object with **all keys present**, even if values are empty:\n",
    "```json\n",
    "{{\n",
    "  \"is_work_opportunity\": true,\n",
    "  \"workplace\": [...],\n",
    "  \"start_date\": [...],\n",
    "  \"end_date\": [...],\n",
    "  \"day_shift_rate\": [...],\n",
    "  \"night_shift_rate\": [...],\n",
    "  \"position\": [...],\n",
    "  \"clean_shaven\": [...],\n",
    "  \"client_name\": [...],\n",
    "  \"contact_number\": [...],\n",
    "  \"email_address\": [...]\n",
    "}}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b730ce-fdfd-4b93-8387-2eaaa67962af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Get current date in YYYY-MM-DD\n",
    "current_year = time.gmtime().tm_year \n",
    "current_month = time.gmtime().tm_mon\n",
    "current_day = time.gmtime().tm_mday \n",
    "current_date = f'{current_year}-{current_month:02d}-{current_day:02d}'\n",
    "\n",
    "PROMPT_INSTRUCTIONS = f\"\"\"\n",
    "You are an expert assistant for detecting job opportunities for **mechanical fitters** or **riggers** in **mining shutdowns** in Australia.\n",
    "\n",
    "Analyze the full email thread content and return a structured JSON object **only if** there is a genuine and current work opportunity. Otherwise, return `\"is_work_opportunity\": false` and leave all other fields as empty lists.\n",
    "\n",
    "## Relevance Criteria\n",
    "Only return a result if the email includes one of:\n",
    "- A job ad, invitation to apply, or request for availability\n",
    "- Shutdown schedule confirmation or a start/end date\n",
    "- (Ignore rosters)\n",
    "\n",
    "## Extraction Fields (all as **lists**):\n",
    "- `workplace`: Names of mines/sites.\n",
    "- `start_date`, `end_date`: Format as `YYYY-MM-DD`. Today is {current_date}.\n",
    "- `day_shift_rate`, `night_shift_rate`: Float values (e.g., 655.00).\n",
    "- `position`: \"Fitter\" or \"Rigger\".\n",
    "- `clean_shaven`: True or False.\n",
    "- `client_name`: Extract from sender's domain; take only the first part (e.g., from `downergroup.com.au` â†’ `downergroup`).\n",
    "- `contact_number`: Digits only, no spaces.\n",
    "- `email_address`: Valid contact emails.\n",
    "\n",
    "> Ensure all lists are the same length. Duplicate or align entries as needed. Use dummy values if specific details are missing.\n",
    "\n",
    "## Output Format\n",
    "Return the following JSON object with **all keys present**, even if values are empty:\n",
    "{{\n",
    "  \"is_work_opportunity\": true,\n",
    "  \"workplace\": [...],\n",
    "  \"start_date\": [...],\n",
    "  \"end_date\": [...],\n",
    "  \"day_shift_rate\": [...],\n",
    "  \"night_shift_rate\": [...],\n",
    "  \"position\": [...],\n",
    "  \"clean_shaven\": [...],\n",
    "  \"client_name\": [...],\n",
    "  \"contact_number\": [...],\n",
    "  \"email_address\": [...]\n",
    "}}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1018110-6637-46f2-94b8-bd9194353b01",
   "metadata": {},
   "source": [
    "## Step 5: Parse and Save Job Offers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e35643",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('OPENAI_API_KEY.txt', 'r') as f:\n",
    "    key_value = f.readline().strip() # Reads the first line and removes whitespace\n",
    "print(OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e54e4d0-da1e-46bc-a5ef-279c570343c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def remove_code_fences(text):\n",
    "    lines = text.strip().splitlines()\n",
    "    if lines and lines[0].strip().startswith(\"```\"):\n",
    "        lines = lines[1:]  # remove first line\n",
    "    if lines and lines[-1].strip() == \"```\":\n",
    "        lines = lines[:-1]  # remove last line\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "def query_gpt_model(email_body, MODEL=\"gpt-4o\", INSTRUCTIONS=PROMPT_INSTRUCTIONS, INPUT=\"\"):\n",
    "    return client.responses.create(\n",
    "        model=MODEL,\n",
    "        instructions=INSTRUCTIONS,\n",
    "        input=INPUT + email_body  # If `input` is expected as a plain prompt\n",
    "    )\n",
    "\n",
    "import json\n",
    "import traceback\n",
    "\n",
    "def process_emails_for_jobs(emails):\n",
    "    job_offers = []\n",
    "\n",
    "    for email_obj in emails:\n",
    "        email_preview = email_obj.get('subject', '')[:50] or email_obj.get('body', '')[:50]\n",
    "        \n",
    "        try:\n",
    "            model_output = query_gpt_model(email_obj['body']).output_text\n",
    "            cleaned_output = remove_code_fences(model_output)\n",
    "            parsed = json.loads(cleaned_output)\n",
    "        except Exception as e:\n",
    "            # Don't debug here â€” only care if it's a work opportunity\n",
    "            continue\n",
    "        \n",
    "        # Only handle if it's flagged as a work opportunity\n",
    "        if parsed.get('is_work_opportunity') is True:\n",
    "            try:\n",
    "                required_keys = ['workplace', 'start_date',\n",
    "                                 'end_date', 'day_shift_rate', 'night_shift_rate', 'position',\n",
    "                                 'clean_shaven', 'client_name', 'contact_number', 'email_address']\n",
    "\n",
    "                # Check key presence\n",
    "                if not all(key in parsed for key in required_keys):\n",
    "                    print(f\"[DEBUG] Missing keys in GPT output for email preview: '{email_preview}'\")\n",
    "                    continue\n",
    "\n",
    "                # Step 1: Collect list lengths\n",
    "                list_lengths = {key: len(parsed[key]) for key in required_keys if isinstance(parsed[key], list)}\n",
    "\n",
    "                # Step 2: Check for inconsistency\n",
    "                if len(set(list_lengths.values())) != 1:\n",
    "                    print(f\"[DEBUG] Inconsistent list lengths in work data for email: '{email_preview}'\")\n",
    "                    for key, length in list_lengths.items():\n",
    "                        print(f\"  - {key}: {length} -> {parsed[key]}\")\n",
    "\n",
    "                    # Step 3: Normalize by padding with last item (or empty string if list is empty)\n",
    "                    max_length = max(list_lengths.values())\n",
    "                    for key in required_keys:\n",
    "                        if isinstance(parsed.get(key), list):\n",
    "                            current_list = parsed[key]\n",
    "                            while len(current_list) < max_length:\n",
    "                                current_list.append(current_list[-1] if current_list else \"\")\n",
    "\n",
    "\n",
    "                # Extract and store job offers\n",
    "                max_len = max(list_lengths.values())\n",
    "                for i in range(max_len):\n",
    "                    job_offers.append({\n",
    "                        'workplace': parsed['workplace'][i],\n",
    "                        'start_date': parsed['start_date'][i],\n",
    "                        'end_date': parsed['end_date'][i],\n",
    "                        'day_shift_rate': parsed['day_shift_rate'][i],\n",
    "                        'night_shift_rate': parsed['night_shift_rate'][i],\n",
    "                        'position': parsed['position'][i],\n",
    "                        'clean_shaven': parsed['clean_shaven'][i],\n",
    "                        'client_name': parsed['client_name'][i],\n",
    "                        'contact_number': parsed['contact_number'][i],\n",
    "                        'email_address': parsed['email_address'][i],\n",
    "                        'email_thread_link': f\"https://mail.google.com/mail/u/0/#inbox/{email_obj['thread_id']}\"\n",
    "                    })\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"[DEBUG] Failed to process work opportunity from email: '{email_preview}'\")\n",
    "                print(f\"[DEBUG] Error: {e}\")\n",
    "                traceback.print_exc()\n",
    "\n",
    "    return job_offers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6fcd38-1c75-432c-baaf-9d07035298b5",
   "metadata": {},
   "source": [
    "## Step 6: Add entries to Google calendar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381e07f0-8939-40d8-9900-d24c56063530",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_google_calendars(calendar_service):\n",
    "    calendars_result = calendar_service.calendarList().list().execute()\n",
    "    calendars = calendars_result.get('items', [])\n",
    "\n",
    "    for cal in calendars:\n",
    "        print(f\"{cal.get('summary')}\\t: {cal.get('id')}\")\n",
    "    \n",
    "# list_google_calendars(calendar_service)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a5bfdc-3789-4edb-916f-aee5a0479021",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_calendar(calendar_service, calendar_id):\n",
    "    page_token = None\n",
    "    while True:\n",
    "        events = calendar_service.events().list(\n",
    "            calendarId=calendar_id,\n",
    "            pageToken=page_token,\n",
    "            showDeleted=False,\n",
    "            maxResults=2500  # API max limit per page\n",
    "        ).execute()\n",
    "\n",
    "        items = events.get('items', [])\n",
    "        if not items:\n",
    "            print(\"No more events to delete.\")\n",
    "            break\n",
    "\n",
    "        for event in items:\n",
    "            try:\n",
    "                calendar_service.events().delete(\n",
    "                    calendarId=calendar_id,\n",
    "                    eventId=event['id']\n",
    "                ).execute()\n",
    "                print(f\"Deleted: {event.get('summary', 'No Title')}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to delete event: {e}\")\n",
    "\n",
    "        page_token = events.get('nextPageToken')\n",
    "        if not page_token:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260df5dd-45f1-4926-9697-2be4da4cb974",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_jobs_to_calendar(job_offers, calendar_service, calendar_id):\n",
    "    for job in job_offers:\n",
    "        summary = f\"{job['workplace']} | ${job['day_shift_rate']}/day & ${job['night_shift_rate']}/night | {job['client_name']}\"\n",
    "        start_date = job['start_date']\n",
    "        end_date = job['end_date']\n",
    "\n",
    "        # Define the event to insert\n",
    "        event = {\n",
    "            'summary': summary,\n",
    "            'description': f\"\"\"\n",
    "Link to Email Thread: {job['email_thread_link']}\n",
    "\n",
    "Site: {job['workplace']}\n",
    "Day Shift Rate: {job['day_shift_rate']}\n",
    "Night Shift Rate: {job['night_shift_rate']}\n",
    "\n",
    "Position: {job['position']}\n",
    "Clean Shaven: {job['clean_shaven']}\n",
    "\n",
    "Contact Email: mailto:{job['email_address']}\n",
    "Phone: tel:{job['contact_number']}\n",
    "\"\"\",\n",
    "            'start': {\n",
    "                'date': start_date,\n",
    "                'timeZone': 'Australia/Perth',\n",
    "            },\n",
    "            'end': {\n",
    "                'date': end_date,\n",
    "                'timeZone': 'Australia/Perth',\n",
    "            },\n",
    "            'event_type': 'workingLocation',\n",
    "            'location': f\"{job['workplace']}\"\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            # Search for existing events with the same summary on the same day\n",
    "            existing_events = calendar_service.events().list(\n",
    "                calendarId=calendar_id,\n",
    "                q=summary,\n",
    "                timeMin=f\"{start_date}T00:00:00+08:00\",\n",
    "                timeMax=f\"{end_date}T23:59:59+08:00\",\n",
    "                singleEvents=True\n",
    "            ).execute()\n",
    "\n",
    "            if existing_events.get('items'):\n",
    "                print(f\"Skipped duplicate event: {summary} on {start_date}\")\n",
    "                continue  # Skip adding this event\n",
    "\n",
    "            # Insert new event\n",
    "            event_result = calendar_service.events().insert(calendarId=calendar_id, body=event).execute()\n",
    "            print(\"Calendar entry added:\", summary, event_result.get('htmlLink'))\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"Failed to add calendar entry:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c77bc77-7692-4e1f-87fd-90719e974818",
   "metadata": {},
   "source": [
    "# TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9354ae-eb92-4c64-85e5-df7b7c4ae309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get access to gmail and calendar\n",
    "gmail_service, calendar_service = authenticate_google_services()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b955a394-0044-4139-89dc-dbe136e1fd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get job offers from emails\n",
    "num_days = 7\n",
    "num_hours = num_days * 24\n",
    "emails = fetch_recent_emails(gmail_service, time_delta_hours=num_hours,max_results=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad2eada-8041-4eb8-889e-f7183fc7562f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count = 0\n",
    "# for email in emails:\n",
    "#     print(f\"Email no. {count} ({email['received_datetime']}) : {email['subject']}\")\n",
    "#     count = count+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21bccdfb-38ba-45ba-976e-3eb39a3475eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_offers = process_emails_for_jobs(emails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70643c4-c42b-42c5-a5ea-904f56e04e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_calendar(calendar_service,calendar_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5677638c",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_jobs_to_calendar(job_offers,calendar_service,calendar_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
